numpy
PhyDecoder                            total [ms]    count [n]        std [ms]       mean [ms]
  +-  query_tf:                       414.84        9853             0.03           0.042           
  +-  matrix_to_pose:                 724.02        9852             0.016          0.073           
  +-  get_side_points:                262.43        3942             0.097          0.067           
  +-  make_footprint_with_node:       713.77        1971             0.159          0.362           
  +-  visualize_plane:                673.41        1970             0.053          0.342           
  +------  state_callback.footprint:  905.22        1971             0.173          0.459           
  +------  make_footprint_with_node.1:94.37         1971             0.028          0.048           
  +------  state_callback.circle:     4207.54       7881             0.98           0.534           
  +------  torchcatgpu:               159.34        1970             0.364          0.081           
  +-  state_callback:                 19115.32      1970             3.478          9.703 
  
  
  torch:
  PhyDecoder                            total [ms]    count [n]        std [ms]       mean [ms]
  +-  query_tf:                       585.02        8913             0.095          0.066           
  +-  matrix_to_pose:                 902.53        8912             0.059          0.101           
  +-  get_side_points:                334.54        3566             0.094          0.094           
  +-  make_footprint_with_node:       1051.46       1783             0.541          0.59            
  +-  visualize_plane:                754.41        1782             0.071          0.423           
  +------  state_callback.footprint:  1365.31       1783             0.666          0.766           
  +------  make_footprint_with_node.1:143.19        1783             0.107          0.08            
  +------  state_callback.circle:     7610.38       7129             1.462          1.068           
  +------  torchcatgpu:               145.48        1782             0.146          0.082           
  +-  state_callback:                 25407.33      1782             6.067          14.258          
Node killed ()
PhyDecoder                            total [ms]    count [n]        std [ms]       mean [ms]
  +-  query_tf:                       585.02        8913             0.095          0.066           
  +-  matrix_to_pose:                 902.53        8912             0.059          0.101           
  +-  get_side_points:                334.54        3566             0.094          0.094           
  +-  make_footprint_with_node:       1051.46       1783             0.541          0.59            
  +-  visualize_plane:                754.41        1782             0.071          0.423           
  +------  state_callback.footprint:  1365.31       1783             0.666          0.766           
  +------  make_footprint_with_node.1:143.19        1783             0.107          0.08            
  +------  state_callback.circle:     7610.38       7129             1.462          1.068           
  +------  torchcatgpu:               145.48        1782             0.146          0.082           
  +-  state_callback:                 25407.33      1782             6.067          14.258 
  
  numba w. polygon make 47.5hz
  PhyDecoder                            total [ms]    count [n]        std [ms]       mean [ms]
  +-  query_tf:                       2137.67       30440            0.585          0.07            
  +-  matrix_to_pose:                 2649.1        30440            0.581          0.087           
  +-  get_side_points:                2081.95       12176            11.661         0.171           
  +-  make_footprint_with_node:       6111.67       6088             27.653         1.004           
  +-  visualize_plane:                2515.85       6087             0.094          0.413           
  +------  state_callback.footprint:  7833.94       6088             27.659         1.287           
  +------  make_footprint_with_node.1:1861.95       6088             11.158         0.306           
  +------  state_callback.circle:     5831.79       24352            17.936         0.239           
  +------  torchcatgpu:               539.87        6087             0.269          0.089           
  +-  state_callback:                 60046.56      6087             99.403         9.865
  
  PhyDecoder                            total [ms]    count [n]        std [ms]       mean [ms]
  +-  query_tf:                       1235.93       19475            0.106          0.063           
  +-  matrix_to_pose:                 1564.55       19475            0.091          0.08            
  +-  get_side_points:                1741.34       7790             14.263         0.224           
  +-  make_footprint_with_node:       3546.92       3895             20.182         0.911           
  +-  visualize_plane:                1462.22       3895             0.065          0.375           
  +------  state_callback.footprint:  4214.32       3895             20.189         1.082           
  +------  make_footprint_with_node.1:537.66        3895             0.279          0.138           
  +------  state_callback.circle:     4844.28       15580            23.543         0.311           
  +------  torchcatgpu:               449.69        3895             1.571          0.115           
  +-  state_callback:                 38629.5       3895             113.656        9.918  
  
  
 Main_process                          total [ms]    count [n]        std [ms]       mean [ms]
  +-  scale_intrinsic:                4.05          1                0.0            4.054           
  +-  broadcast_tf_from_matrix:       288.48        86               3.283          3.354           
  +-  visualize_main_graph:           2270.01       85               19.86          26.706          
  +-  camera_callback:                24555.33      1310             102.014        18.745          
  +-  phy_decoder_callback:           51689.64      895              175.265        57.754          
Manager                               total [ms]    count [n]        std [ms]       mean [ms]
  +-  train:                          64019.41      10               19204.732      6401.941        
  +-  add_main_node:                  1438.82       85               19.316         16.927          
  +-  update_visualization_node:      300.04        41               7.765          7.318           
  +-  add_sub_node:                   18800.72      138              206.979        136.237         
  +------  reprojection_main:         9798.78       63               228.731        155.536         
  +------  reprojection_main_1:       8857.24       143              134.247        61.939          
  +------  query:                     63314.03      1                0.0            63314.027       
  +------  into VDdataset:            7.27          1                0.0            7.274           
  +-  make_batch_to_dataset:          63333.18      1                0.0            63333.18  
      
Main_process                          total [ms]    count [n]        std [ms]       mean [ms]
  +-  scale_intrinsic:                4.84          1                0.0            4.835           
  +-  phy_decoder_callback:           15648.64      1353             55.212         11.566          
  +-  broadcast_tf_from_matrix:       192.1         59               3.426          3.256           
  +-  visualize_main_graph:           1368.2        59               17.262         23.19           
  +-  camera_callback:                17060.47      919              136.727        18.564          
  +-  learning_thread_loop:           60865.27      1                0.0            60865.27        
Manager                               total [ms]    count [n]        std [ms]       mean [ms]
  +-  train:                          34542.41      13               3303.54        2657.108        
  +-  add_sub_node:                   5087.17       115              100.079        44.236          
  +-  add_main_node:                  559.83        59               8.513          9.489           
  +-  update_visualization_node:      420.21        35               32.834         12.006          
  +------  reprojection_main:         2615.61       53               131.009        49.351          
  +------  reprojection_main_1:       2185.39       117              82.059         18.679          
  +------  query:                     34050.77      8                3276.401       4256.347        
  +------  into VDdataset:            0.75          8                0.05           0.093           
  +-  make_batch_to_dataset:          34101.62      8                3272.193       4262.703



Fast:
Manager                               total [ms]    count [n]        std [ms]       mean [ms]
  +-  train:                          976.39        11               111.725        88.762          
  +-  add_sub_node:                   1827.01       44               108.858        41.523          
  +-  add_main_node:                  129.62        23               2.972          5.636           
  +-  update_visualization_node:      274.06        13               49.196         21.081          
  +------  reprojection_main:         1251.78       13               175.385        96.291          
  +------  reprojection_main_1:       1080.32       30               116.874        36.011          
  +------  query:                     425.54        5                52.881         85.108          
  +------  into VDdataset:            1.34          5                0.291          0.267           
  +-  make_batch_to_dataset:          495.68        5                62.489         99.135 
  def query_valid_batch(self,fast=True):
        """ Since the feat is compressed with ratio info in dict, we need to query the valid feat
            given supervision_signal_valid ---> get the dataset for model training
            
            Return:
                valid_feats: (num_valid, C)
                valid_masks: (num_valid, C (=2))
        """
        # transfer the features to the same device as supervision_mask
        if self._is_feat_compressed:
            temp_feat={}
            for key, value in self._features.items():
                temp_feat[key] = value.to(self._supervision_mask.device)
        else:
            temp_feat=self._features.to(self._supervision_mask.device)
        
        used_combin=[]
        
        # first check the real ratio is equal to the ratio in dict
        if not self._is_feat_compressed:
            return temp_feat
        else:
            _,H_s,W_s=self._supervision_signal_valid.shape
            valid_feats = []
            valid_masks=[]
            for key, value in temp_feat.items():
                B,C,H,W=value.shape
                if H_s/H!=key[0] or W_s/W!=key[1]:
                    raise ValueError("The ratio in feats dict is not equal to the real ratio")

                valid_indices = torch.where(self._supervision_signal_valid[0] == 1)
                ratio_h,ratio_w=key
                if not fast:
                    i=0
                    for h_idx, w_idx in zip(*valid_indices):
                        i=i+1 
                        patch_h_idx = h_idx // ratio_h
                        patch_w_idx = w_idx // ratio_w
                        # skip the repeated feat
                        if (patch_h_idx,patch_w_idx) in used_combin:
                            continue
                        # Extract the mask
                        mask_vec=self._supervision_mask[:,h_idx,w_idx]
                        valid_masks.append(mask_vec)
                        
                        # idx to tensor int
                        patch_h_idx=int(patch_h_idx)
                        patch_w_idx=int(patch_w_idx)
                        # Extract the feature vector for the corresponding patch
                        feat_vec = value[:, :, patch_h_idx, patch_w_idx]
                        valid_feats.append(feat_vec)
                        # record the used combination
                        used_combin.append((patch_h_idx,patch_w_idx))
                    return torch.cat(valid_feats,dim=0),torch.stack(valid_masks,dim=0)
                
                
                # Vectorize the computation of patch indices
                h_indices, w_indices = valid_indices
                patch_h_indices = h_indices // ratio_h
                patch_w_indices = w_indices // ratio_w
                # Identify unique indices and corresponding unique masks and features
                unique_indices, inverse_indices = torch.unique(torch.stack([patch_h_indices, patch_w_indices], dim=1), 
                                                            dim=0, 
                                                            return_inverse=True)
                selected_feats=value[:, :, unique_indices[:, 0], unique_indices[:, 1]]
                selected_feats=selected_feats.squeeze(0).permute(1,0)
                # Initialize a list to store the selected masks corresponding to each unique index
                selected_masks = []

                # Iterate over unique indices
                for idx in range(unique_indices.shape[0]):
                    # Find the first occurrence of the unique index in the inverse_indices
                    ss=torch.where(inverse_indices == idx)[0]
                    original_idx = torch.where(inverse_indices == idx)[0][0]

                    # Extract the corresponding mask using the original valid indices
                    mask = self._supervision_mask[:, h_indices[original_idx], w_indices[original_idx]]

                    selected_masks.append(mask)

                # Stack the selected masks
                selected_masks = torch.stack(selected_masks, dim=0)
            return selected_feats,selected_masks

